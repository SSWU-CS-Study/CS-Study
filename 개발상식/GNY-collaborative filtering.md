# 추천알고리즘- 협업 필터링

분야: 개발상식
생성 일시: 2023년 5월 21일 오전 10:04

**목차**

<aside>
💭 면접 질문 정리

1. 추천 알고리즘의 종류에 대해 설명하세요
    - 콘텐츠만을 활용해 추천해주는 콘텐츠 기반 필터링 모델과 협업 필터링 방식이 있다.
2. 협업 필터링이란?
    - 다른 사용자들로부터 취향 정보를 모아 사용자의 관심사를 예측하는 방식을 의미한다.
3. 메모리기반 접근 방식의 특징은?
    - 사용자와 아이템을 사용한 기존 데이터의 유사도를 기반으로 동작하는 방식
4. 메모리 기반 접근 방식의 단점은?
    - 데이터가 축적되지 않은 경우와 희소 데이터의 경우 성능이 낮으며 확장가능성이 낮다.
5. 모델 기반 접근 방식의 특징은?
    - 기계 학습을 통해 사용자 또는 아이템의 숨겨진 특성 값을 계산하는 방식
6. 모델 기반 접근 방식의 장단점은?
    - 적은 데이터로도 처리가 가능하나 결과의 설명력이 낮다
7. 협업 필터링의 한계점에 대해 설명하세요
    - 콜드 스타트, 계산 효율 저하, 롱테일 문제
8. 협업기반 필터링의 한계점의 극복 대안은?
    - “협업 필터링"과 "콘텐츠 기반 필터링"을 조합한 하이브리드 추천 시스템 사용

</aside>

---

# 0. 추천 시스템

> 콘텐츠 기반 필터링 모델 vs 협업 필터링 모델
> 

<aside>
📎 **추천 시스템이란?**

영화를 추천 받고 싶을 때 우리가 하는 행동

1. 내가 좋아하는 감독, 장르, 키워드의 영화를 찾아본다 
    
    → **Content Based Filtering**
    
2. 나랑 성향이 비슷한 친구들이 본 영화를 찾아본다
    
    → **협업 필터링(Collaborative Filetering)**
    
</aside>

## 1. 콘텐츠 기반 필터링 모델(Content-based Filtering)

> 콘텐츠만을 활용해 추천해주는 알고리즘
> 
- 사용자가 좋아하는 콘텐츠를 분석하여 그와 유사한 콘텐츠를 추천해주는 기술
- 예를 들어 사용자가 “summer”라는 노래를 감상했다면, 이를 바탕으로 여름과 관련된 노래를 추천해주는 방식
- 새로운 아이템이 출시된 경우 아이템을 사용한 사용자의 데이터가 없기 때문에 콘텐츠 기반 필터링 모델을 사용해  텍스트나 이미지 유사성 기반의 추천이 가능

![스크린샷 2023-05-21 10.32.33.png](%E1%84%8E%E1%85%AE%E1%84%8E%E1%85%A5%E1%86%AB%E1%84%8B%E1%85%A1%E1%86%AF%E1%84%80%E1%85%A9%E1%84%85%E1%85%B5%E1%84%8C%E1%85%B3%E1%86%B7-%20%E1%84%92%E1%85%A7%E1%86%B8%E1%84%8B%E1%85%A5%E1%86%B8%20%E1%84%91%E1%85%B5%E1%86%AF%E1%84%90%E1%85%A5%E1%84%85%E1%85%B5%E1%86%BC%20dc437d2f35624fd18d03e5fe59293a08/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-05-21_10.32.33.png)

## 2. 협업 필터링 모델(Collaborative Filtering, CF)

![스크린샷 2023-05-21 10.32.42.png](%E1%84%8E%E1%85%AE%E1%84%8E%E1%85%A5%E1%86%AB%E1%84%8B%E1%85%A1%E1%86%AF%E1%84%80%E1%85%A9%E1%84%85%E1%85%B5%E1%84%8C%E1%85%B3%E1%86%B7-%20%E1%84%92%E1%85%A7%E1%86%B8%E1%84%8B%E1%85%A5%E1%86%B8%20%E1%84%91%E1%85%B5%E1%86%AF%E1%84%90%E1%85%A5%E1%84%85%E1%85%B5%E1%86%BC%20dc437d2f35624fd18d03e5fe59293a08/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-05-21_10.32.42.png)

> 다른 사용자들로부터 취향 정보를 모아 사용자의 관심사를 예측하는 방식
> 
- 비슷한 취향을 가진 사용자들은 어떠한 아이템에 대해 비슷한 선호도를 가질 것이라는 가정 하에 사용자와 아이템 간 상호 작용 데이터를 활용한다
- “**많은 사용자들**"로 부터 얻은 취향 정보를 활용
- 사용자의 취향 정보를 집단 지성으로 활용하여 추천한다.
- 만약 <벌새> 를 좋아하는 사람들이 공통적으로 한국 독립영화에 대해 높은 선호도를 보인다면 사용자에게 <메기>를 추천
- 협업 필터링 모델은 사용자와 아이템 간의 상호작용을 바탕으로 하기 때문에 텍스트/이미지 기반 유사성이 높지 않더라도, 사용자가 함께 구매한 아이템을 추천

# 1. 협업 필터링

## 1.1 메모리 기반 접근 방식(Memory Based Approach)

> 가장 전통적인 접근 방식이며 유사한 사용자(Users)나 아이템(Item) → 기존 데이터 의 유사도를 기반으로 동작
> 
- 사용자 간 유사도를 기준으로 하는 경우에는 **사용자 기반 추천,** 아이템 간 유사도를 기준으로 하는 경우에는 **아이템 기반 추천**
- 최적화 방법(Optimization)이나, 훈련(Train)이 필요 없으며 매개변수를 학습하지 않음.
- 단순한 산술 연산만 사용
- 쉽게 구현이 가능하며 결과의 설명력이 좋으며 도메인에 의존적이지 않다
- 데이터가 축적되지 않은 경우와 희소 데이터의 경우 성능이 낮으며( 비교 대상이 적으면, 성능저하 ) 확장가능성이 낮음( 비교 대상이 많아지면, 계산량이 증가)

![스크린샷 2023-05-21 11.18.47.png](%E1%84%8E%E1%85%AE%E1%84%8E%E1%85%A5%E1%86%AB%E1%84%8B%E1%85%A1%E1%86%AF%E1%84%80%E1%85%A9%E1%84%85%E1%85%B5%E1%84%8C%E1%85%B3%E1%86%B7-%20%E1%84%92%E1%85%A7%E1%86%B8%E1%84%8B%E1%85%A5%E1%86%B8%20%E1%84%91%E1%85%B5%E1%86%AF%E1%84%90%E1%85%A5%E1%84%85%E1%85%B5%E1%86%BC%20dc437d2f35624fd18d03e5fe59293a08/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-05-21_11.18.47.png)

### a. 사용자 기반 추천 **(User-based Recommendation)**

![스크린샷 2023-05-21 10.37.16.png](%E1%84%8E%E1%85%AE%E1%84%8E%E1%85%A5%E1%86%AB%E1%84%8B%E1%85%A1%E1%86%AF%E1%84%80%E1%85%A9%E1%84%85%E1%85%B5%E1%84%8C%E1%85%B3%E1%86%B7-%20%E1%84%92%E1%85%A7%E1%86%B8%E1%84%8B%E1%85%A5%E1%86%B8%20%E1%84%91%E1%85%B5%E1%86%AF%E1%84%90%E1%85%A5%E1%84%85%E1%85%B5%E1%86%BC%20dc437d2f35624fd18d03e5fe59293a08/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-05-21_10.37.16.png)

- 비슷한 성향을 지닌 사용자들을 그룹화하여, 그룹이 선호하는 상품을 해당 그룹에 속한 사용자에게 추천
- “평점 유사도"를 기반으로 나와 유사한 사용자(Users)들을 찾음
- 유사한 사용자가 좋아한 Item을 추천 → 당신과 비슷한 사용자 "ㄱ"은, "B"영화도 좋아했습니다
- 사용자 A와 B가 비슷한 성향을 가지고 있는데, B가 아이스크림을 좋아한다면 A역시 아이스크림을 좋아할 것이라고 예측하고 관련 정보를 추천
- 인스타그램 같은 SNS의 친구 추천→ 나의 팔로워를 나와 비슷한 성향을 가진 사람으로 인식하고 그의 또 다른 팔로워들을 나에게 추천함

### b. **아이템 기반 추천 (Item-based Recommendation)**

![스크린샷 2023-05-21 10.38.06.png](%E1%84%8E%E1%85%AE%E1%84%8E%E1%85%A5%E1%86%AB%E1%84%8B%E1%85%A1%E1%86%AF%E1%84%80%E1%85%A9%E1%84%85%E1%85%B5%E1%84%8C%E1%85%B3%E1%86%B7-%20%E1%84%92%E1%85%A7%E1%86%B8%E1%84%8B%E1%85%A5%E1%86%B8%20%E1%84%91%E1%85%B5%E1%86%AF%E1%84%90%E1%85%A5%E1%84%85%E1%85%B5%E1%86%BC%20dc437d2f35624fd18d03e5fe59293a08/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-05-21_10.38.06.png)

- 사용자가 이전에 구매했던 아이템을 기반으로 그 상품과 유사한 다른 상품을 추천하는 방식
- 상품 간 유사도는 함께 구매되는 경우의 빈도를 분석하여 측정
- 특정 Item을 좋아한 사용자들을 찾음 → 그 사용자들이 공통적으로 좋아했던 다른 Item을 찾음 → 이 아이템을 좋아한 사용자는, "B"영화도 좋아했습니다

### c. 알고리즘(유사도 측정)

> 메모리 기반 접근 방식은 유사도(거리) 를 측정하여 사용함
> 

이 때 두 사용자 간의 유사도는 두 벡터 간의 유사도로 정의할 수 있다.거리 측정 방법은 다양하며 일반적으로는 행렬을 사용한다. (사용자- 행, 아이템 - 열)  두 벡터 간 유사도를 구하기 위해서 일반적으로 코사인 유사도(Cosine Similarity)와 피어슨 유사도(Pearson Similarity)입니다.

- 코사인 유사도
    - 코사인 유사도는 두 벡터의 코사인 각도를 계산하여 유사성을 측정한다. 
    코사인 함수를 생각해보면 0도에서의 값이 1, 180도에서의 값이 -1. 
    두 벡터가 서로 가까우면 각도가 작아서 값이 1에 가까워져 유사하다고 하고, 두 벡터가 서로 대척되면 각도가 커져서 값이 -1에 가까워져 유사하지 않다고 하는 것. 이를 직관적으로 이해하면 두 벡터가 가리키는 방향이 얼마나 유사한가를 의미
        
        ![스크린샷 2023-05-21 10.41.27.png](%E1%84%8E%E1%85%AE%E1%84%8E%E1%85%A5%E1%86%AB%E1%84%8B%E1%85%A1%E1%86%AF%E1%84%80%E1%85%A9%E1%84%85%E1%85%B5%E1%84%8C%E1%85%B3%E1%86%B7-%20%E1%84%92%E1%85%A7%E1%86%B8%E1%84%8B%E1%85%A5%E1%86%B8%20%E1%84%91%E1%85%B5%E1%86%AF%E1%84%90%E1%85%A5%E1%84%85%E1%85%B5%E1%86%BC%20dc437d2f35624fd18d03e5fe59293a08/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-05-21_10.41.27.png)
        
        ![스크린샷 2023-05-21 10.41.44.png](%E1%84%8E%E1%85%AE%E1%84%8E%E1%85%A5%E1%86%AB%E1%84%8B%E1%85%A1%E1%86%AF%E1%84%80%E1%85%A9%E1%84%85%E1%85%B5%E1%84%8C%E1%85%B3%E1%86%B7-%20%E1%84%92%E1%85%A7%E1%86%B8%E1%84%8B%E1%85%A5%E1%86%B8%20%E1%84%91%E1%85%B5%E1%86%AF%E1%84%90%E1%85%A5%E1%84%85%E1%85%B5%E1%86%BC%20dc437d2f35624fd18d03e5fe59293a08/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-05-21_10.41.44.png)
        
- 피어슨 유사도
    - 피어슨 유사도(Pearson Similarity)는 두 벡터의 상관계수(Pearson correlation coefficient)를 말하며 다음과 같이 정의.
        
        ![스크린샷 2023-05-21 10.42.28.png](%E1%84%8E%E1%85%AE%E1%84%8E%E1%85%A5%E1%86%AB%E1%84%8B%E1%85%A1%E1%86%AF%E1%84%80%E1%85%A9%E1%84%85%E1%85%B5%E1%84%8C%E1%85%B3%E1%86%B7-%20%E1%84%92%E1%85%A7%E1%86%B8%E1%84%8B%E1%85%A5%E1%86%B8%20%E1%84%91%E1%85%B5%E1%86%AF%E1%84%90%E1%85%A5%E1%84%85%E1%85%B5%E1%86%BC%20dc437d2f35624fd18d03e5fe59293a08/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-05-21_10.42.28.png)
        
        계산된 피어슨 유사도가 1이면 양의 상관관계(비교하는 데이터 중 하나가 증가하면 다른 하나도 증가함), -1이면 음의 상관관계(하나가 증가하면 다른 하나는 감소함), 0이면 상관관계가 없음(독립)을 의미함.
        
        <aside>
        💭 예시
        
        |  | 벌새 | 윤희에게 | 토르 | 미나리 | 인어공주 |
        | --- | --- | --- | --- | --- | --- |
        | A | 5 | 4 | 4 | 3 |  |
        | B | 1 | 0 | 1 |  | 4 |
        | C | 4 | 4 |  | 5 | 3 |
        | D |  | 2 | 1 | 4 | 3 |
        | E | 4 |  | 4 | 4 | 2 |
        | F | 4 | 2 | 3 |  | 1 |
        
        코사인 유사도를 이용해 B와 D의 유사도를 구해보면 ,   두 사용자가 공통으로 평가한 항목(윤희에게, 토르, 인어공주)에 대해서만 계산하기 때문에, u=(0, 1, 4), v=(2, 1, 3)으로 두고 계산하면 유사도는 다음과 같다
        
        ![스크린샷 2023-05-21 10.48.59.png](%E1%84%8E%E1%85%AE%E1%84%8E%E1%85%A5%E1%86%AB%E1%84%8B%E1%85%A1%E1%86%AF%E1%84%80%E1%85%A9%E1%84%85%E1%85%B5%E1%84%8C%E1%85%B3%E1%86%B7-%20%E1%84%92%E1%85%A7%E1%86%B8%E1%84%8B%E1%85%A5%E1%86%B8%20%E1%84%91%E1%85%B5%E1%86%AF%E1%84%90%E1%85%A5%E1%84%85%E1%85%B5%E1%86%BC%20dc437d2f35624fd18d03e5fe59293a08/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-05-21_10.48.59.png)
        
        | similarity | A | B | C | D | E | F |
        | --- | --- | --- | --- | --- | --- | --- |
        | A | 1 | 0.84 | 0.96 | 0.82 | 0.98 | 0.98 |
        | B | 0.84 | 1 | 0.61 | 0.84 | 0.63 | 0.47 |
        | C | 0.96 | 0.61 | 1 | 0.97 | 0.99 | 0.92 |
        | D | 0.82 | 0.84 | 0.97 | 1 | 0.85 | 0.71 |
        | E | 0.98 | 0.63 | 0.99 | 0.85 | 1 | 0.98 |
        | F | 0.98 | 0.47 | 0.92 | 0.71 | 0.98 | 1 |
        
        이를 활용하여 특정 인물이 평가하지 않았던 영화에 대한 평가 점수를 예측해볼 수 있음
        예를 들어 가장 유사한 몇명의 점수를 이용하여 예측 점수로 구할 수도 있고, 전체를 대상으로 유사도 기반의 [weighted sum](https://en.wikipedia.org/wiki/Weighted_sum_model) 값을 예측 점수로 사용
        E의 윤희에게 에 대한 평가 점수를 2번째 방법으로 예측해보면  다음과 같다 
        
        ![스크린샷 2023-05-21 10.54.04.png](%E1%84%8E%E1%85%AE%E1%84%8E%E1%85%A5%E1%86%AB%E1%84%8B%E1%85%A1%E1%86%AF%E1%84%80%E1%85%A9%E1%84%85%E1%85%B5%E1%84%8C%E1%85%B3%E1%86%B7-%20%E1%84%92%E1%85%A7%E1%86%B8%E1%84%8B%E1%85%A5%E1%86%B8%20%E1%84%91%E1%85%B5%E1%86%AF%E1%84%90%E1%85%A5%E1%84%85%E1%85%B5%E1%86%BC%20dc437d2f35624fd18d03e5fe59293a08/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-05-21_10.54.04.png)
        
        </aside>
        

## 1.2 모델 기반 접근 방식(Model Based Approach)

> 기계 학습을 통해 사용자 또는 아이템의 숨겨진 특성 값을 계산
> 
- 잠재요인을 이용한 Latent Factor 방식과 Classification/Regression(분류/회귀)방식 및 최신 융합 모델 방식을 이용한 다양한 접근 방식 존재
- **기본 아이디어** : 사용자의 선호도는 소수의 Hidden Factor로 결정될 수 있다!
    - Hidden Factor를 **Embedding** 이라고도 부름
        - * Embedding 이란 : Item과 User에 대한 압축된 저차원(Low-dimensional) Hidden Factor
- 최적화 방법이나 매개변수를 학습함
- 적은 데이터로도 처리가 가능함
- 결과의 설명력이 낮음

### a. **Latent Factor 모델/ 행렬 분해(Matrix Factorization)**

![스크린샷 2023-05-21 10.38.59.png](%E1%84%8E%E1%85%AE%E1%84%8E%E1%85%A5%E1%86%AB%E1%84%8B%E1%85%A1%E1%86%AF%E1%84%80%E1%85%A9%E1%84%85%E1%85%B5%E1%84%8C%E1%85%B3%E1%86%B7-%20%E1%84%92%E1%85%A7%E1%86%B8%E1%84%8B%E1%85%A5%E1%86%B8%20%E1%84%91%E1%85%B5%E1%86%AF%E1%84%90%E1%85%A5%E1%84%85%E1%85%B5%E1%86%BC%20dc437d2f35624fd18d03e5fe59293a08/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-05-21_10.38.59.png)

- 사용자와 아이템을 잠재적인 차원(Factor)들을 사용해 나타낼 수 있다고 가정하는 모델
- 차원은 축(axis)과 같은 의미로 사용됨
- 예를 들어 x축에는 성별을 나타내고 y축에는 영화의 장르를 나타내는 좌표평면이 있다면, 사용자와 아이템은 좌표평면 위의 적절한 x, y 값에 매핑
- 사용자 = (-2.5, -3.2), 영화 = (1.5, 4.6)  → 사용자와 아이템을 x축과 y축의 두 가지 차원으로 표현했지만 실제 Latent Factor 방식에서는 차원이 무엇을 의미하는지 알 수 없으며, 차원의 개수 또한 여러개일 수 있습니다.
- 사용자와 아이템의 매핑 지점이 가까울수록 유사하다고 판단

### b. **Classification/Regression 방식(분류/회귀)**

- Classification/Regression 방식은 콘텐츠 기반 추천 방식과 쉽게 융합이 가능
- 피처 *X* 가 주어졌을 때, 라벨 *y*를 예측하는 구조이기 때문에, 피드백 *y*를 예측하는 상황에서,  *X*에 콘텐츠 관련 정보를 피처로 만들어서 추가하면, 피드백 데이터뿐만 아니라 콘텐츠 데이터를 활용한 추천이 가능
- 구체적으로 Classification은 유저의 성향에 따라 군집을 분류하여 성향이 부여된 군집에 맞추어  아이템을 추천해 주는 방식이고, Regression은 유저와 아이템에 대한 평균 평점을 구하는 모델을  통해 새로운 카테고리에서 예측값을 예측하여 추천하는 방식

### c. 알고리즘

이 방법은 머신러닝 알고리즘을 통해, 사용자가 아직 평가하지 않은 아이템의 평점을 예측함. 사용자의 선호도가 소수의 잠재된 요인으로 결정될 수 있다는 아이디어를 바탕으로 하기 때문에 행렬 분해를 이용하여 잠재된 요인을 추출

![스크린샷 2023-05-21 10.55.15.png](%E1%84%8E%E1%85%AE%E1%84%8E%E1%85%A5%E1%86%AB%E1%84%8B%E1%85%A1%E1%86%AF%E1%84%80%E1%85%A9%E1%84%85%E1%85%B5%E1%84%8C%E1%85%B3%E1%86%B7-%20%E1%84%92%E1%85%A7%E1%86%B8%E1%84%8B%E1%85%A5%E1%86%B8%20%E1%84%91%E1%85%B5%E1%86%AF%E1%84%90%E1%85%A5%E1%84%85%E1%85%B5%E1%86%BC%20dc437d2f35624fd18d03e5fe59293a08/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-05-21_10.55.15.png)

행렬 분해는 User-Item Matrix를 F차원의 User와 Item의 latent factor 행렬곱으로 분해하는 방법을 말합니다. User-Item Matrix의 유저 u의 아이템 i에 대한 선호도는 다음과 같이 User/Item Latent Matrix의 벡터의 곱으로 표현될 수 있습니다. 이 표현을 통해 유저가 평가하지 않은 선호도에 대해서도아래의 수식을 통해 쉽게 추정할 수 있으며 내적 값이 높을수록 유저 u에게 아이템 i가 더 좋은 추천이라는 것을 알 수 있다.

## 1.3 한계점

### a. 콜드 스타트 (Cold start)

> "**새로 시작할 때의 곤란함**"
> 
- 기존 데이터 (User-Item 행렬)가 충분하게 구축되어야 함
- 사용자 기반 추천방식에서는 신규 사용자의 행동이 기록되지 않으면, 어떤 아이템도 추천하지 못한다는 문제가 발생
- 아이템 기반 추천방식에서도, 신규 상품이 출시되더라도 이를 추천할 수 있는 정보가 쌓일 때까지 추천을 할 수 없음
- 시스템이 아직 충분한 정보를 모으지 못하면 사용자에 대한 추론을 이끌어 내지 못해 추천을 할 수 없는 한계 존재

### b. 계산 효율 저하

- 협업 필터링(Collaborative Fitlering)은 계산량이 많은 알고리즘
- 사용자가 많아질수록 계산 시간 증가
- 사용자가 많아야 정확한 추천 결과를 내지만, 동시에 계산 시간도 증가됨

→  알고리즘의 정확도와 걸리는 시간이라는 상충되는 문제점은 협업 필터링의 딜레마

### c. 롱테일(Long-Tail) 문제

![스크린샷 2023-05-21 11.42.22.png](%E1%84%8E%E1%85%AE%E1%84%8E%E1%85%A5%E1%86%AB%E1%84%8B%E1%85%A1%E1%86%AF%E1%84%80%E1%85%A9%E1%84%85%E1%85%B5%E1%84%8C%E1%85%B3%E1%86%B7-%20%E1%84%92%E1%85%A7%E1%86%B8%E1%84%8B%E1%85%A5%E1%86%B8%20%E1%84%91%E1%85%B5%E1%86%AF%E1%84%90%E1%85%A5%E1%84%85%E1%85%B5%E1%86%BC%20dc437d2f35624fd18d03e5fe59293a08/%25E1%2584%2589%25E1%2585%25B3%25E1%2584%258F%25E1%2585%25B3%25E1%2584%2585%25E1%2585%25B5%25E1%2586%25AB%25E1%2584%2589%25E1%2585%25A3%25E1%2586%25BA_2023-05-21_11.42.22.png)

- 파레토 법칙(전체 결과의 80%가 전체 원인의 20%에서 일어나는 현상)을 그래프로 나타내었을 때 
꼬리처럼 긴 부분을 형성하는 80%의 부분을 롱테일이라고 함
- 사용자들이 관심을 많이 보이는 소수의 인기 있는 콘텐츠를 주로 추천하게 되어 ‘비대칭적 쏠림 현상'이 발생
- 품질 좋은 Long-Tail 아이템은 추천되지 못하여, 추천의 다양성이 떨어지게 됨

## 1.4. 극복

### a. **콘텐츠 기반 필터링(Contents-Based Filtering)**

> 콘텐츠에 대한 분석을 기반으로 추천
> 
- 예시 : 영화 - 감독, 장르, 등장인물 등 / 상품 - 상품설명, 종류
- **장점** :  많은 사용자의 행동 정보가 필요하지 않으며 콜드 스타트(Cold Start) 문제 해소 가능
- **단점** :
    - 1) **메타 정보의 한정성** : 상품의 프로파일을 모두 함축하는데 한계가 있음 → 정밀성이 떨어짐
    - 2) 개인의 성향을 세부적으로 파악하기 어려움
- **방법**
    - 1) 50명의 태거(Tagger)에 의해서 사람이 직접 콘텐츠의 태그를 달게 한다.
        - 넷플릭스는 사람이 태그를 달아 콘텐츠를 5만 종으로 나눔
    - 2)  기계학습 : 텍스트 마이닝으로 분석

### b. **하이브리드(Hybrid) 추천 시스템**

> “협업 필터링"과 "콘텐츠 기반 필터링"을 조합
> 
- 데이터 쌓이기 전 : 콘텐츠 기반 필터링을 통해, 콜드 스타트 문제 해결
- 데이터 쌓이기 후 : 협업 필터링으로 추천의 정확성을 높임

### c. **머신러닝 추천 시스템**

- 사용자의 조회, 클릭 등의 사소한 행동까지 학습
- 사용자에게 추천할 후보군 제안 → 사용자의 반응을 학습 → 점점 더 정교한 결과 도출

---

참고 : [https://deepdaiv.oopy.io/articles/1#e0d6ab55-9dbd-494a-a9eb-15b0f3af6184](https://deepdaiv.oopy.io/articles/1#e0d6ab55-9dbd-494a-a9eb-15b0f3af6184)
